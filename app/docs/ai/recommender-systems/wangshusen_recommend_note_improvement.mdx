---
title: '王树森推荐系统学习笔记_提指标'
description: ""
date: "2025-09-27"
tags:
  - tag-one
---

# 王树森推荐系统学习笔记_提指标

## 涨指标的方法

### 涨指标的方法

#### 推荐系统的评价指标

- 日活用户数（$DAU$）和留存是最核心的指标。
- 目前工业界最常用 $LT7$ 和 $LT30$ 衡量留存。
  - 某用户今天（$t_0$）登录 APP，未来 7 天（$t_0 \sim t_6$）中有 4 天登录 APP，那么该用户今天（$t_0$）的 $LT7$ 等于 4。
  - 显然有 $1 \leq LT7 \leq 7$ 和 $1 \leq LT30 \leq 30$。
  - $LT$ 增长通常意味着用户体验提升。（除非 $LT$ 增长且 $DAU$ 下降。）
  - 假设 APP 禁止低活用户登录，则 $DAU$ 下降，$LT$ 增长。

- 其他核心指标：用户使用时长、总阅读数（即总点击数）、总曝光数。这些指标的重要性低于 $DAU$ 和留存。
  - 时长增长，$LT$ 通常会增长。
  - 时长增长，阅读数、曝光数可能会下降。

- 非核心指标：点击率、交互率、等等。
- 对于 UGC 平台，发布量和发布渗透率也是核心指标。

#### 涨指标的方法有哪些？

1. 改进召回模型，添加新的召回模型。
2. 改进粗排和精排模型。
3. 提升召回、粗排、精排中的多样性。
4. 特殊对待新用户、低活用户等特殊人群。
5. 利用关注、转发、评论这三种交互行为。

### 涨指标的方法：召回

**召回模型 & 召回通道**

- 推荐系统有几十条召回通道，它们的召回总量是固定的。总量越大，指标越好，粗排计算量越大。
- 双塔模型（$two\text{-}tower$）和 $item\text{-}to\text{-}item$（$I2I$）是最重要的两类召回模型，占据召回的大部分配额。
- 有很多小众的模型，占据的配额很少。在召回总量不变的前提下，添加某些召回模型可以提升核心指标。
- 有很多内容池，比如 30 天物品、1 天物品、6 小时物品、新用户优质内容池、分人群内容池。
- 同一个模型可以用于多个内容池，得到多条召回通道。

#### 改进双塔模型

**方向1：优化正样本、负样本。**

- **简单正样本**：有点击的（用户，物品）二元组。
- **简单负样本**：随机组合的（用户，物品）二元组。
- **困难负样本**：排序靠后的（用户，物品）二元组。

**方向2：改进神经网络结构。**

- **Baseline**：用户塔、物品塔分别是全连接网络，各输出一个向量，分别作为用户、物品的表征。
- **改进**：用户塔、物品塔分别用 $DCN$ 代替全连接网络。
- **改进**：在用户塔中使用用户行为序列（$last\text{-}n$）。
- **改进**：使用多向量模型代替单向量模型。（标准的双塔模型也叫单向量模型。）

![](https://raw.githubusercontent.com/H0SH123/Books-and-Notes/main/RecommenderSystem/images/8-2-1.png)

**方向3：改进模型的训练方法。**

- **Baseline**：做二分类，让模型学会区分正样本和负样本。
- **改进**：结合二分类、$batch$ 内负采样。（对于 $batch$ 内负采样，需要做纠偏。）
- **改进**：使用自监督学习方法，让冷门物品的 $embedding$ 学得更好。

#### Item-to-Item (I2I)

- $I2I$ 是一大类模型，基于相似物品做召回。
- 最常见的用法是 $U2I2I$（$user \rightarrow item \rightarrow item$）。
  - 用户 $u$ 喜欢物品 $i_1$（用户历史上交互过的物品）。
  - 寻找 $i_1$ 的相似物品 $i_2$（即 $I2I$）。
  - 将 $i_2$ 推荐给 $u$。

- 如何计算物品相似度？
- 方法1：ItemCF 及其变体。
  - 一些用户同时喜欢物品 $i_1$ 和 $i_2$，则认为 $i_1$ 和 $i_2$ 相似。
  - $ItemCF$、$Online\ ItemCF$、$Swing$、$Online\ Swing$ 都是基于相同的思想。
  - 线上同时使用上述 4 种 $I2I$ 模型，各分配一定配额。
- 方法2：基于物品向量表征，计算向量相似度。（双塔模型、图神经网络均可计算物品向量表征。）

#### 小众的召回模型

**类似 I2I 的模型**

- **U2U2I**（$user \rightarrow user \rightarrow item$）：已知用户 $u_1$ 与 $u_2$ 相似，且 $u_2$ 喜欢物品 $i$，那么给用户 $u_1$ 推荐物品 $i$。
- **U2A2I**（$user \rightarrow author \rightarrow item$）：已知用户 $u$ 喜欢作者 $a$，且 $a$ 发布物品 $i$，那么给用户 $u$ 推荐物品 $i$。
- **U2A2A2I**（$user \rightarrow author \rightarrow author \rightarrow item$）：已知用户 $u$ 喜欢作者 $a_1$，且 $a_1$ 与 $a_2$ 相似，$a_2$ 发布物品 $i$，那么给用户 $u$ 推荐物品 $i$。

#### 总结：改进召回模型

- **双塔模型**：优化正负样本、改进神经网络结构、改进训练的方法。
- **I2I 模型**：同时使用 $ItemCF$ 及其变体，使用物品向量表征计算物品相似度。
- **添加小众的召回模型**，比如 $PDN$、$Deep\ Retrieval$、$SINE$、$M2GRL$ 等模型。
- **在召回总量不变的前提下，调整各召回通道的配额**。（可以让各用户群体用不同的配额。）

### 涨指标的方法：排序模型

**排序模型**

1. 精排模型的改进
2. 粗排模型的改进
3. 用户行为序列建模
4. 在线学习
5. 老汤模型

#### 精排模型的改进

![](https://raw.githubusercontent.com/H0SH123/Books-and-Notes/main/RecommenderSystem/images/8-3-1.png)



**精排模型：基座**

- 基座的输入包括离散特征和连续特征，输出一个向量，作为多目标预估的输入。
- **改进 1**：基座加宽加深，计算量更大，预测更准确。
- **改进 2**：做自动的特征交叉，比如 $bilinear$ [1] 和 $LHUC$ [2]。
- **改进 3**：特征工程，比如添加统计特征、多模态内容特征。

**精排模型：多目标预估**

- 基于基座输出的向量，同时预估点击率等多个目标。
- **改进 1**：增加新的预估目标，并把预估结果加入融合公式。
  - 最标准的目标包括点击率、点赞率、收藏率、转发率、评论率、关注率、完播率……
  - 寻找更多目标，比如进入评论区、给他人写的评论点赞……
  - 把新的预估目标加入融合公式。

- **改进 2**：$MMoE$、$PLE$ 等结构可能有效，但往往无效。
- **改进 3**：纠正 $position\ bias$ 可能有效，也可能无效。

#### 粗排模型的改进

**粗排模型**

- 粗排的打分量比精排大 10 倍，因此粗排模型必须够快。
- **简单模型**：多向量双塔模型，同时预估点击率等多个目标。
- **复杂模型**：三塔模型效果好，但工程实现难度较大。

**粗精排一致性建模**

- 蒸馏精排训练粗排，让粗排与精排更一致。
- **方法1**：pointwise 蒸馏。
  - 设 $y$ 是用户真实行为，设 $p$ 是精排的预估。
  - 用 $\frac{y + p}{2}$ 作为粗排拟合的目标。
  - **例**：
    - 对于点击率目标，用户有点击（$y=1$），精排预估 $p=0.6$。
    - 用 $\frac{y + p}{2} = 0.8$ 作为粗排拟合的点击率目标。

- **方法2**：pairwise 或 listwise 蒸馏。
  - 给定 $k$ 个候选物品，按照精排预估做排序。
  - 做 learning to rank ($LTR$)，让粗排拟合物品的序（而非值）。
  - **例**：
    - 对于物品 $i$ 和 $j$，精排预估点击率为 $p_i > p_j$。
    - $LTR$ 鼓励粗排预估点击率满足 $q_i > q_j$，否则有惩罚。
    - $LTR$ 通常使用 pairwise logistic loss。

- **优点**：粗精排一致性建模可以提升核心指标。
- **缺点**：如果精排出 bug，精排预估值 $p$ 有偏，会污染粗排训练数据。

#### 用户行为序列建模

![](https://raw.githubusercontent.com/H0SH123/Books-and-Notes/main/RecommenderSystem/images/8-3-2.png)

- 最简单的方法是对物品向量取平均，作为一种用户特征。
- $DIN$ 使用注意力机制，对物品向量做加权平均。
- 工业界目前沿着 $SIM$ 的方向发展。先用类别等属性筛选物品，然后用 $DIN$ 对物品向量做加权平均。

**用户行为序列建模**

- **改进1**：增加序列长度，让预测更准确，但是会增加计算成本和推理时间。
- **改进2**：筛选的方法，比如用类别、物品向量表征聚类。
  - 离线用多模态神经网络提取物品内容特征，将物品表征为向量。
  - 离线将物品向量聚类为 1000 类，每个物品有一个聚类序号。
  - 线上排序时，用户行为序列中有 $n = 1,000,000$ 个物品。某候选物品的聚类序号是 70，对 $n$ 个物品做筛选，只保留聚类序号为 70 的物品。$n$ 个物品中只有数千个被保留下来。
  - 同时有好几种筛选方法，取筛选结果的并集。

- **改进3**：对用户行为序列中的物品，使用 ID 以外的一些特征。
- **概括**：沿着 $SIM$ 的方向发展，让原始的序列尽量长，然后做筛选降低序列长度，最后将筛选结果输入 $DIN$。

#### 在线学习

![](https://raw.githubusercontent.com/H0SH123/Books-and-Notes/main/RecommenderSystem/images/8-3-3.png)

![](https://raw.githubusercontent.com/H0SH123/Books-and-Notes/main/RecommenderSystem/images/8-3-4.png)

**在线学习的资源消耗**

- 既需要在凌晨做全量更新，也需要全天不断做增量更新。
- 设在线学习需要 10,000 $CPU\ core$ 的算力增量更新一个精排模型。推荐系统一共需要多少额外的算力给在线学习？
- 为了做 $AB$ 测试，线上同时运行多个不同的模型。
- 如果线上有 $m$ 个模型，则需要 $m$ 套在线学习的机器。
- 线上有 $m$ 个模型，其中 1 个是 $holdout$，1 个是推全的模型，$m-2$ 个测试的新模型。

- 每套在线学习的机器成本都很大，因此 $m$ 数量很小，制约模型开发迭代的效率。
- 在线学习对指标的提升巨大，但是会制约模型开发迭代的效率。

![](https://raw.githubusercontent.com/H0SH123/Books-and-Notes/main/RecommenderSystem/images/8-3-5.png)

#### 老汤模型

- 用每天新产生的数据对模型做 1 $epoch$ 的训练。
- 久而久之，老模型训练得非常好，很难被超过。
- 对模型做改进，重新训练，很难追上老模型……
- **问题 1**：如何快速判断新模型结构是否优于老模型？（不需要追上线上的老模型，只需要判断新老模型谁的结构更优。）
  - 对于新、老模型结构，都随机初始化模型全连接层。
  - $Embedding$ 层可以是随机初始化，也可以是复用老模型训练好的参数。
  - 用 $n$ 天的数据训练新老模型。（从旧到新，训练 1 $epoch$）
  - 如果新模型显著优于老模型，新模型很可能更优。
  - 只是比较新老模型结构谁更好，而非真正追平老模型。
- **问题 2**：如何更快追平、超过线上的老模型？（只有几十天的数据，新模型就能追上训练上百天的老模型。）
  - 已经得出初步结论，认为新模型很可能优于老模型。用几十天的数据训练新模型，早日追平老模型。
  - **方法 1**：尽可能多地复用老模型训练好的 $embedding$ 层，避免随机初始化 $embedding$ 层。（$Embedding$ 层是对用户、物品特征的“记忆”，比全连接层学得慢。）
  - **方法 2**：用老模型做 $teacher$，蒸馏新模型。（用户真实行为是 $y$，老模型的预测是 $p$，用 $\frac{y + p}{2}$ 作为训练新模型的目标。）

#### 总结：改进排序模型

- **精排模型**：改进模型基座（加宽加深、特征交叉、特征工程），改进多目标预估（增加新目标、$MMoE$、$position\ bias$）。
- **粗排模型**：三塔模型（取代多向量双塔模型），粗精排一致性建模。
- **用户行为序列建模**：沿着 $SIM$ 的方向迭代升级，加长序列长度，改进筛选物品的方法。
- **在线学习**：对指标提升大，但是会降低模型迭代升级效率。
- **老汤模型** 制约模型迭代升级效率，需要特殊技巧。

### 涨指标的方法：提升多样性

#### 排序的多样性

**精排多样性**

- **精排阶段**，结合兴趣分数和多样性分数对物品 $i$ 排序。
  - $s_i$：兴趣分数，即融合点击率等多个预估目标。
  - $d_i$：多样性分数，即物品 $i$ 与已选中的物品的差异。
  - 用 $s_i + d_i$ 对物品做排序。

- 常用 MMR$、$DPP 等方法计算多样性分数，精排使用滑动窗口，粗排不使用滑动窗口。
  - 精排决定最终的曝光，曝光页面上邻近的物品相似度应该小。所以计算精排多样性要使用滑动窗口。
  - 粗排要考虑整体的多样性，而非一个滑动窗口中的多样性。

- 除了多样性分数，精排还使用打散策略增加多样性。
  - **类目**：当前选中物品 $i$，之后 5 个位置不允许跟 $i$ 的二级类目相同。
  - **多模态**：事先计算物品多模态内容向量表征，将全库物品聚为 1000 类；在精排阶段，如果当前选中物品 $i$，之后 10 个位置不允许跟 $i$ 同属一个聚类。

**粗排多样性**

- 粗排给 5000 个物品打分，选出 500 个物品送入精排。
- 提升粗排和精排多样性都可以提升推荐系统核心指标。
- 根据 $s_i$ 对 5000 个物品排序，分数最高的 200 个物品送入精排。
- 对于剩余的 4800 个物品，对每个物品 $i$ 计算兴趣分数 $s_i$ 和多样性分数 $d_i$。
- 根据 $s_i + d_i$ 对剩余 4800 个物品排序，分数最高的 300 个物品送入精排。

#### 召回的多样性

**双塔模型：添加噪声**

- 用户塔将用户特征作为输入，输出用户的向量表征；然后做 $ANN$ 检索，召回向量相似度高的物品。
- 线上做召回时（在计算出用户向量之后，在做 $ANN$ 检索之前），往用户向量中添加随机噪声。
- 用户的兴趣越窄（比如用户最近交互的 $n$ 个物品只覆盖少数几个类目），则添加的噪声越强。
- 添加噪声使得召回的物品更多样，可以提升推荐系统核心指标。

**双塔模型：抽样用户行为序列**

- 用户最近交互的 $n$ 个物品（用户行为序列）是用户塔的输入。
- 保留最近的 $r$ 个物品（$r \ll n$）。
- 从剩余的 $n - r$ 个物品中随机抽样 $t$ 个物品（$t \ll n$）。（可以是均匀抽样，也可以用非均匀抽样让类目平衡。）
- 将得到的 $r + t$ 个物品作为用户行为序列，而不是用全部 $n$ 个物品。
- **抽样用户行为序列为什么能涨指标？**
  - 一方面，注入随机性，召回结果更多样化。
  - 另一方面，$n$ 可以非常大，可以利用到用户很久之前的兴趣。

**U2I2I：抽样用户行为序列**

- $U2I2I$（$user \to item \to item$）中的第一个 $item$ 是指用户最近交互的 $n$ 个物品之一，在 $U2I2I$ 中叫作**种子物品**。
- $n$ 个物品覆盖的类目数较少，且类目不平衡。
  - 系统共有 200 个类目，某用户的 $n$ 个物品只覆盖 15 个类目。
  - 足球类目的物品有 $0.4n$ 个，电视剧类目的物品有 $0.2n$ 个，其余类目的物品数均少于 $0.05n$ 个。

- 做非均匀随机抽样，从 $n$ 个物品中选出 $t$ 个，让类目平衡。（想法和效果与双塔中的用户行为序列抽样相似。）
- 用抽样得到的 $t$ 个物品（代替原本的 $n$ 个物品）作为 $U2I2I$ 的种子物品。
- 一方面，类目更平衡，多样性更好。另一方面，$n$ 可以更大，覆盖的类目更多。

**探索流量**

- 每个用户曝光的物品中有 2% 是非个性化的，用作兴趣探索。
- 维护一个精选内容池，其中物品均为交互率指标高的优质物品。（内容池可以分人群，比如 30~40 岁男性内容池。）
- 从精选内容池中随机抽样几个物品，跳过排序，直接插入最终排序结果。
- 兴趣探索在短期内负向影响核心指标，但长期会产生正向影响。

#### 总结：提升多样性

- **精排**：结合兴趣分数和多样性分数做排序；做规则打散。
- **粗排**：只用兴趣分数选出部分物品；结合兴趣分数和多样性分数选出部分物品。
- **召回**：往双塔模型的用户向量添加噪声；对用户行为序列做非均匀随机抽样（对双塔和 U2I2I 都适用）。
- **兴趣探索**：保留少部分的流量给非个性化推荐。

### 涨指标的方法：特殊对待特殊人群

**为什么要特殊对待特殊人群**？

1. 新用户、低活用户的行为很少，个性化推荐不准确。
2. 新用户、低活用户容易流失，要想办法促使他们留存。
3. 特殊用户的行为（比如点击率、交互率）不同于主流用户，基于全体用户行为训练出的模型在特殊用户人群上有偏。

**涨指标的方法**

1. 构造特殊内容池，用于特殊用户人群的召回。
2. 使用特殊排序策略，保护特殊用户。
3. 使用特殊的排序模型，消除模型预估的偏差。

#### 构造特殊的内容池

**特殊内容池**

- 为什么需要特殊内容池？
- 新用户、低活用户的行为很少，个性化召回不准确。(既然个性化不好，那么就保证内容质量好。)
- 针对特定人群的特点构造特殊内容池，提升用户满意度。例如，对于喜欢留下评论的中年女性，构造促进评论内容池，满足这些用户的互动需求。

**如何构造特殊内容池**

- 方法 1：根据物品获得的交互次数、交互率选择优质物品。
  - 圈定人群：只考虑特定人群，例如 18~25 岁二线城市男性。
  - 构造内容池：用该人群对物品的交互次数、交互率给物品打分，选出分数最高的物品进入内容池。
  - 内容池有弱个性化的效果。
  - 内容池定期更新，加入新物品，排除交互率低和失去时效性的老物品。
  - 该内容池只对该人群生效。
- 方法 2：做因果推断，判断物品对人群留存率的贡献，根据贡献值选物品。

**特殊内容池的召回**

- 通常使用双塔模型从特殊内容池中做召回。
  - 双塔模型是个性化的。
  - 对于新用户，双塔模型的个性化做不准。
  - 靠高质量内容、弱个性化做弥补。

- 额外的训练代价？
  - 对于正常用户，不论有多少内容池，只训练一个双塔模型。
  - 对于新用户，由于历史交互记录很少，需要单独训练模型。

- 额外的推理代价？
  - 内容池定期更新，然后需要更新 ANN 索引。
  - 线上做召回时，需要做 ANN 检索。
  - 特殊内容池都很小（比全量内容池小 10~100 倍），所以需要的额外算力不大。

#### 特殊的排序策略

差异化的排序模型

- 特殊用户⼈群的行为不同于普通用户。新用户、低活用户的点击率、交互率偏高或偏低。
- 排序模型被主流用户主导，对特殊用户做不准预估。
  - 用全体用户数据训练出的模型，给新用户做的预估有严重偏差。
  - 如果⼀个APP的用90%是女性，用全体⽤户数据训练出的模型， 对男性用户做的预估有偏差。
- 问题：对于特殊用户，如何让排序模型预估做得准？

- **方法 1：大模型 + 小模型。**
  - 用全体用户行为训练大模型，大模型的预估 $p$ 拟合用户行为 $y$。
  - 用特殊用户的行为训练小模型，小模型的预估 $q$ 拟合大模型的残差 $y - p$。
  - 对主流用户只用大模型做预估 $p$。
  - 对特殊用户，结合大模型和小模型的预估 $p + q$。

- **方法 2：融合多个 experts，类似 MMoE。**
  - 只用一个模型，模型有多个 experts，各输出一个向量。
  - 对 experts 的输出做加权平均。
  - 根据用户特征计算权重。
  - 以新用户为例，模型将用户的新老、活跃度等特征作为输入，输出权重，用于对 experts 做加权平均。

- **方法 3：大模型预估之后，用小模型做校准。**
  - 用大模型预估点击率、交互率。
  - 将用户特征、大模型预估点击率和交互率作为小模型（例如 GBDT）的输入。
  - 在特殊用户人群的数据上训练小模型，小模型的输出拟合用户真实行为。

**错误的做法**

- 每个用户人群使用一个排序模型，推荐系统同时维护多个大模型。
  - 系统有一个主模型；每个用户人群有自己的一个模型。
  - 每天凌晨，用全体用户数据更新主模型。
  - 基于训练好的主模型，在某特殊用户人群的数据上再训练 1 epoch，作为该用户人群的模型。

- 短期可以提升指标；维护代价大，长期有害。
  - 起初，低活男性用户模型比主模型的 AUC 高 0.2%。
  - 主模型迭代几个版本后，AUC 累计提升 0.5%。
  - 特殊人群模型太多，长期没有人维护和更新。
  - 如果把低活男性用户模型下线，换成主模型，在低活男性用户上的 AUC 反倒提升 0.3%！

#### 总结：特殊对待特殊用户人群

- **召回**：针对特殊用户人群，构造特殊的内容池，增加相应的召回通道。
- **排序策略**：排除低质量物品，保护新用户和低活用户；特殊用户人群使用特殊的融分公式。
- **排序模型**：结合大模型和小模型，小模型拟合大模型的残差；只用一个模型，模型有多个 experts；大模型预估之后，用小模型做校准。

### 涨指标的方法：利用交互行为

#### 关注

**关注量对留存的价值**

- 对于一位用户，他关注的作者越多，则平台对他的吸引力越强。
- 用户留存率（$r$）与他关注的作者数量（$f$）正相关。
- 如果某用户的 $f$ 较小，则推荐系统要促使该用户关注更多作者。

- 如何利用关注关系提升用户留存？
- 方法 1：用排序策略提升关注量。
  - 对于用户 $u$，模型预估候选物品 $i$ 的关注率为 $p_i$。
  - 设用户 $u$ 已经关注了 $f$ 个作者。
  - 我们定义单调递减函数 $w(f)$，用户已经关注的作者越多，则 $w(f)$ 越小。
  - 在排序融分公式中添加 $w(f) \cdot p_i$，用于促关注。（如果 $f$ 小且 $p_i$ 大，则 $w(f) \cdot p_i$ 给物品 $i$ 带来很大加分。）

- 方法 2：构造促关注内容池和召回通道。
  - 这个内容池中物品的关注率高，可以促关注。
  - 如果用户关注的作者数 $f$ 较小，则对该用户使用该内容池。
  - 召回配额可以固定，也可以与 $f$ 负相关。

**粉丝数对促发布的价值**

- UGC 平台将作者发布量、发布率作为核心指标，希望作者多发布。
- 作者发布的物品被平台推送给用户，会产生点赞、评论、关注等交互。
- 交互（尤其是关注、评论）可以提升作者发布积极性。
- 作者的粉丝数越少，则每增加一个粉丝对发布积极性的提升越大。

- 用排序策略帮助低粉新作者涨粉。
- 某作者 $a$ 的粉丝数（被关注数）为 $f_a$。
- 作者 $a$ 发布的物品 $i$ 可能被推荐给用户 $u$，模型预估关注率为 $p_{ui}$。
- 我们定义单调递减函数 $w(f_a)$ 作为权重；作者 $a$ 的粉丝越多，则 $w(f_a)$ 越小。
- 在排序融分公式中添加 $w(f_a) \cdot p_{ui}$，帮助低粉作者涨粉。

**隐式关注关系**

- **召回通道 U2A2I**：user → author → item。
- **显式关注关系**：用户 $u$ 关注了作者 $a$，将 $a$ 发布的物品推荐给 $u$。（点击率、交互率指标通常高于其他召回通道。）
- **隐式关注关系**：用户 $u$ 喜欢看作者 $a$ 发布的物品，但是 $u$ 没有关注 $a$。
- **隐式关注的作者数量远大于显式关注**。挖掘隐式关注关系，构造 U2A2I 召回通道，可以提升推荐系统核心指标。

#### 转发（分享）

**促转发（分享回流）**

- A 平台用户将物品转发到 B 平台，可以为 A 吸引站外流量。
- 推荐系统做促转发（也叫分享回流）可以提升 DAU 和消费指标。
- 简单提升转发次数是否有效呢？
  - 模型预估转发率为 $p$，融分公式中有一项 $w \cdot p$，让转发率大的物品更容易获得曝光机会。
  - 增大权重 $w$ 可以促转发，吸引站外流量，但是会负面影响点击率和其他交互率。

**KOL 建模**

- 目标：在不损害点击和其他交互的前提下，尽量多吸引站外流量。
- 什么样的用户的转发可以吸引大量站外流量？ 其他平台的 Key Opinion Leader (KOL)！
- 如何判断本平台的用户是不是其他平台的 KOL？
- 该用户历史上的转发能带来多少站外流量。

- 方法2：构造促转发内容池和召回通道，对站外KOL⽣效。

#### 评论

**评论促发布**

- UGC 平台 将作者发布量、发布率作为核心指标，希望作者多发布。
- 关注、评论等交互 可以提升作者发布积极性。
- 如果新发布物品尚未获得很多评论，则给预估评论率提权，让物品尽快获得评论。
- 排序融分公式中添加额外一项 $w_i \cdot p_i$。
  - $w_i$：权重，与物品 $i$ 已有的评论数量负相关。
  - $p_i$：为用户推荐物品 $i$，模型预估的评论率。

**评论的其他价值**

- 有的用户喜欢留言评论，喜欢跟作者、评论区用户互动。
  - 给这样的用户添加促评论的内容池，让他们更多机会参与讨论。
  - 有利于提升这些用户的留存。

- 有的用户常留高质量评论（评论的点赞量高）。
  - 高质量评论对作者、其他用户的留存有贡献。（作者、其他用户觉得这样的评论有趣或者有帮助。）
  - 用排序和召回策略鼓励这些用户多留评论。

#### 总结：利用交互行为

- **关注**：  
  - **留存价值**（让新用户关注更多作者，提升新用户留存）。  
  - **发布价值**（帮助新作者获得更多粉丝，提升作者发布积极性）。  
  - **利用隐式关注关系做召回**。

- **转发**：判断哪些用户是站外的 KOL，利用他们转发的价值，吸引站外的流量。

- **评论**：  
  - **发布价值**（促使新物品获得评论，提升作者发布积极性）。  
  - **留存价值**（给喜欢讨论的用户创造更多留言机会）。  
  - **鼓励高质量评论的用户多留评论**。
