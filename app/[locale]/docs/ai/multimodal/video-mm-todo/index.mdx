---
title: "多模态视频大模型"
description: "学习笔记：细粒度感知与长视频理解问题"
status: note
---

# 多模态视频大模型学习笔记

## 1. 背景

多模态视频大模型（MVM）结合了视觉、语言、音频等信息。  
相比图像模型，视频任务难度更大，主要痛点是：

- **细粒度感知**：需要精准定位视频中的对象、动作、关系。
- **长视频理解**：需要跨越长时间跨度，抓取关键事件并保持全局一致性。

---

## 2. 细粒度感知问题

### 2.1 现象

- 识别动作不够细，比如“拿起” vs “举起”容易混淆。
- 模型回答缺少时间戳或关键帧作为证据。
- 不同模态（字幕 vs 画面）不同步。

### 2.2 难点

- **数据**：精细标注成本高，长尾动作样本稀少。
- **计算**：高分辨率视频导致 token 数量暴涨。
- **表征**：局部细节 vs 全局语义之间的矛盾。

### 2.3 方法

- 动作/事件的**分层建模**：全局 -> 局部 -> 原子动作。
- **Token 剪枝 / 压缩**：保留关键帧或关键patch，减少冗余。
- **多任务训练**：分类 + 定位 + QA 联合学习。
- **证据可视化**：输出 frame index 或 bounding box。

---

## 3. 长视频理解问题

### 3.1 现象

- 模型只能处理几秒视频，超过几分钟就“遗忘”。
- 问答缺乏全局上下文，经常答非所问。
- 摘要或检索偏向“局部”，忽略主线。

### 3.2 难点

- **Token 预算**：分钟级视频动辄几十万帧，不可能直接全输入。
- **结构复杂**：电影/课堂/会议往往包含多场景、多角色、多事件。
- **跨模态异步**：字幕、音频、动作不一定同时发生。

### 3.3 方法

- **层次化建模**：Shot → Scene → Event → Video。
- **检索增强**：先通过索引定位关键片段，再送入大模型推理。
- **记忆机制**：滑窗+缓存、外部记忆库、摘要链。
- **多模态协作**：结合字幕（ASR）、OCR、音频，辅助视觉。

---

## 4. 常见评测指标

- **细粒度感知**：
  - 动作定位 mAP@tIoU
  - QA 正确率 + 时间戳一致性
  - 可解释性（证据帧与答案匹配度）
- **长视频理解**：
  - QA 准确率（长上下文）
  - 检索 Recall@K / mAP
  - 摘要质量（ROUGE、人类评价）
  - 计算效率（fps、显存占用）

---

## 5. 其他思考

- 细粒度问题更像 **计算机视觉 + NLP 联合的小任务**（检测/分割/动作识别 + QA）。
- 长视频理解更像 **系统工程**：需要数据预处理（分段/索引）、模型（层次化）、推理（检索+规划）。
- 未来方向可能是：**多模态协同记忆 + 可解释推理**。

---

## 6. 参考文献

- Feather the Throttle: Revisiting Visual Token Pruning — [arXiv:2412.13180](https://arxiv.org/abs/2412.13180)
- Token Activation Map to Visually Explain Multimodal LLMs — [arXiv:2506.23270](https://arxiv.org/abs/2506.23270)
- GLM-4.5V / 4.1V-Thinking — [arXiv:2507.01006](https://arxiv.org/abs/2507.01006)
- Thinking with Images for Multimodal Reasoning — [arXiv:2506.23918](https://arxiv.org/abs/2506.23918)
- Vision as a Dialect — [arXiv:2506.18898](https://arxiv.org/abs/2506.18898)
